{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user opencv-python\n",
    "#!pip install --user --upgrade pip\n",
    "#!python -m pip install --user pip==9.0.3 --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                             #to read an image\n",
    "import numpy as np                     #array in python\n",
    "import scipy.signal as signal          #signal processing\n",
    "import scipy.fftpack as fftpack        #Discrete fourier transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy transforming RGB to YIQ color \n",
    "def rgb2ntsc(src):\n",
    "    [rows,cols]=src.shape[:2] #creates a tuple with row and column number and assigns to the variables\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64) #dst is 3X3X3 matrix, type float and all values equals 0.0\n",
    "    T = np.array([[0.114, 0.587, 0.298], [-0.321, -0.275, 0.596], [0.311, -0.528, 0.212]])\n",
    "    #T = np.array([[0.299, 0.587, 0.114], [0.596, -0.275, -0.321], [0.212, -0.523, 0.311]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert YIQ to RBG\n",
    "def ntsc2rbg(src):\n",
    "    [rows, cols] = src.shape[:2]\n",
    "    dst=np.zeros((rows,cols,3),dtype=np.float64)\n",
    "    T = np.array([[1, -1.108, 1.705], [1, -0.272, -0.647], [1, 0.956, 0.620]])\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            dst[i, j]=np.dot(T,src[i,j])\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyramid, or pyramid representation, is a type of multi-scale signal representation developed by the computer vision, image processing and signal processing communities, in which a signal or an image is subject to repeated smoothing and subsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowpass pyramid: \n",
    "A lowpass pyramid is made by smoothing the image with an appropriate smoothing filter and then subsampling the smoothed image, usually by a factor of 2* along each coordinate direction. The resulting image is then subjected to the same procedure, and the cycle is repeated multiple times. Each cycle of this process results in a smaller image with increased smoothing, but with decreased spatial sampling density (that is, decreased image resolution). If illustrated graphically, the entire multi-scale representation will look like a pyramid, with the original image on the bottom and each cycle's resulting smaller image stacked one atop the other. \n",
    "\n",
    "* level0=original image, level1=1/2 resolution, level2=1/4 resolution\n",
    "\n",
    "#### Bandpass pyramid:\n",
    "A bandpass pyramid is made by forming the difference between images at adjacent levels in the pyramid and performing some kind of image interpolation between adjacent levels of resolution, to enable computation of pixelwise differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we used to work with an image of constant size. But in some occassions, we need to work with images of different resolution of the same image. For example, while searching for something in an image, like face, we are not sure at what size the object will be present in the image. In that case, we will need to create a set of images with different resolution and search for object in all the images. These set of images with different resolution are called Image Pyramids (because when they are kept in a stack with biggest image at bottom and smallest image at top look like a pyramid)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Gaussian pyramid, subsequent images are weighted down using a Gaussian average (Gaussian blur) and scaled down. Each pixel containing a local average that corresponds to a pixel neighborhood on a lower level of the pyramid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher level (Low resolution) in a Gaussian Pyramid is formed by removing consecutive rows and columns in Lower level (higher resolution) image. Then each pixel in higher level is formed by the contribution from 5 pixels in underlying level with gaussian weights. By doing so, a M X N image becomes M/2 X N/2 image. So area reduces to one-fourth of original area. It is called an Octave. The same pattern continues as we go upper in pyramid (ie, resolution decreases). Similarly while expanding, area becomes 4 times in each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Gaussian Pyramid\n",
    "def build_gaussian_pyramid(src,level=3):\n",
    "    s=src.copy()\n",
    "    pyramid=[s]\n",
    "    for i in range(level):\n",
    "        s=cv2.pyrDown(s)\n",
    "        pyramid.append(s)\n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplacian Pyramids are formed from the Gaussian Pyramids. There is no exclusive function for that. Laplacian pyramid images are like edge images only. Most of its elements are zeros. They are used in image compression. A level in Laplacian Pyramid is formed by the difference between that level in Gaussian Pyramid and expanded version of its upper level in Gaussian Pyramid. \n",
    "\n",
    "A Laplacian pyramid is very similar to a Gaussian pyramid but saves the difference image of the blurred versions between each levels. Only the smallest level is not a difference image to enable reconstruction of the high resolution image using the difference images on higher levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Laplacian Pyramid\n",
    "def build_laplacian_pyramid(src,levels=3):\n",
    "    gaussianPyramid = build_gaussian_pyramid(src, levels)\n",
    "    pyramid=[]\n",
    "    for i in range(levels,0,-1):\n",
    "        GE=cv2.pyrUp(gaussianPyramid[i])\n",
    "        L=cv2.subtract(gaussianPyramid[i-1],GE)\n",
    "        pyramid.append(L)\n",
    "    return pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load video from file\n",
    "def load_video(video_filename):\n",
    "    cap=cv2.VideoCapture(video_filename) #creating videocapture object to read the input file\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    video_tensor=np.zeros((frame_count,height,width,3),dtype='float')\n",
    "    x=0\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        if ret is True:\n",
    "            video_tensor[x]=frame\n",
    "            x+=1\n",
    "        else:\n",
    "            break\n",
    "    return video_tensor,fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply temporal ideal bandpass filter to gaussian video\n",
    "def temporal_ideal_filter(tensor,low,high,fps,axis=0):\n",
    "    fft=fftpack.fft(tensor,axis=axis)\n",
    "    frequencies = fftpack.fftfreq(tensor.shape[0], d=1.0 / fps)\n",
    "    bound_low = (np.abs(frequencies - low)).argmin()\n",
    "    bound_high = (np.abs(frequencies - high)).argmin()\n",
    "    fft[:bound_low] = 0\n",
    "    fft[bound_high:-bound_high] = 0\n",
    "    fft[-bound_low:] = 0\n",
    "    iff=fftpack.ifft(fft, axis=axis)\n",
    "    return np.abs(iff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build gaussian pyramid for video\n",
    "def gaussian_video(video_tensor,levels=3):\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_gaussian_pyramid(frame,level=levels)\n",
    "        gaussian_frame=pyr[-1]\n",
    "        if i==0:\n",
    "            vid_data=np.zeros((video_tensor.shape[0],gaussian_frame.shape[0],gaussian_frame.shape[1],3))\n",
    "        vid_data[i]=gaussian_frame\n",
    "    return vid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amplify the video\n",
    "def amplify_video(gaussian_vid,amplification=50):\n",
    "    return gaussian_vid*amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstract video from original video and gaussian video\n",
    "def reconstract_video(amp_video,origin_video,levels=3):\n",
    "    final_video=np.zeros(origin_video.shape)\n",
    "    for i in range(0,amp_video.shape[0]):\n",
    "        img = amp_video[i]\n",
    "        for x in range(levels):\n",
    "            img=cv2.pyrUp(img)\n",
    "        img=img+origin_video[i]\n",
    "        final_video[i]=img\n",
    "    return final_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save video to files\n",
    "def save_video(video_tensor):\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    [height,width]=video_tensor[0].shape[0:2]\n",
    "    writer = cv2.VideoWriter(\"out.avi\", fourcc, 30, (width, height), 1)\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        writer.write(cv2.convertScaleAbs(video_tensor[i]))\n",
    "    writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magnify color\n",
    "def magnify_color(video_name,low,high,levels=3,amplification=20):\n",
    "    t,f=load_video(video_name)\n",
    "    gau_video=gaussian_video(t,levels=levels)\n",
    "    filtered_tensor=temporal_ideal_filter(gau_video,low,high,f)\n",
    "    amplified_video=amplify_video(filtered_tensor,amplification=amplification)\n",
    "    final=reconstract_video(amplified_video,t,levels=3)\n",
    "    save_video(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build laplacian pyramid for video\n",
    "def laplacian_video(video_tensor,levels=3):\n",
    "    tensor_list=[]\n",
    "    for i in range(0,video_tensor.shape[0]):\n",
    "        frame=video_tensor[i]\n",
    "        pyr=build_laplacian_pyramid(frame,levels=levels)\n",
    "        if i==0:\n",
    "            for k in range(levels):\n",
    "                tensor_list.append(np.zeros((video_tensor.shape[0],pyr[k].shape[0],pyr[k].shape[1],3)))\n",
    "        for n in range(levels):\n",
    "            tensor_list[n][i] = pyr[n]\n",
    "    return tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#butterworth bandpass filter\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    omega = 0.5 * fs\n",
    "    low = lowcut / omega\n",
    "    high = highcut / omega\n",
    "    b, a = signal.butter(order, [low, high], btype='band')\n",
    "    y = signal.lfilter(b, a, data, axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstract video from laplacian pyramid\n",
    "def reconstract_from_tensorlist(filter_tensor_list,levels=3):\n",
    "    final=np.zeros(filter_tensor_list[-1].shape)\n",
    "    for i in range(filter_tensor_list[0].shape[0]):\n",
    "        up = filter_tensor_list[0][i]\n",
    "        for n in range(levels-1):\n",
    "            up=cv2.pyrUp(up)+filter_tensor_list[n + 1][i]#可以改为up=cv2.pyrUp(up)\n",
    "        final[i]=up\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manify motion\n",
    "def magnify_motion(video_name,low,high,levels=3,amplification=20):\n",
    "    t,f=load_video(video_name)\n",
    "    lap_video_list=laplacian_video(t,levels=levels)\n",
    "    filter_tensor_list=[]\n",
    "    for i in range(levels):\n",
    "        filter_tensor=butter_bandpass_filter(lap_video_list[i],low,high,f)\n",
    "        filter_tensor*=amplification\n",
    "        filter_tensor_list.append(filter_tensor)\n",
    "    recon=reconstract_from_tensorlist(filter_tensor_list)\n",
    "    final=t+recon\n",
    "    save_video(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    #magnify_color(\"cup1_input.mp4\",0.4,3)\n",
    "    magnify_motion(\"baby_input.mp4\",0.4,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
